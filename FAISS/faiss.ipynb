{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6b30878e",
      "metadata": {},
      "source": [
        "FAISS is a library efficient similarity search and clusturing of dense vector\n",
        "\n",
        "Key Advantages :\n",
        "1) Extremely Fast Similarity Search\n",
        "2) Memory Efficient\n",
        "3) Support GPU acceleration\n",
        "4) Can Hangle millions of vectors\n",
        "\n",
        "\n",
        "Working :\n",
        " - Indexes Vector for fast nearest neightbour search\n",
        " - Returns most similar vectors based on distance metrics\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "c3815e54",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Libraries required for the working\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import numpy as np # for cosine similarity function\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Langchain core imports\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser # How everything inside the chain will be printed\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "# LangChain Specific Imports\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# Vector store\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "\n",
        "from langchain_community.document_loaders import TextLoader, PyPDFLoader\n",
        "from langchain.chains import create_retrieval_chain\n",
        "# from langchain.chains.combine_documents import create_stuff_documents_chain\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "732a5ac3",
      "metadata": {},
      "source": [
        "- Before load_dotenv() - the python program can't see .env file directly\n",
        "- Once load_dotenv() is loaded, it has access to all the variables inside .env file\n",
        "- Using os.getenv(\"API_KEY\") : we can access the variable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "4ef390d6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load the environment variable\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "accfc5d1",
      "metadata": {},
      "source": [
        "Step 1: Having all the data in Document Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "f1b07451",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'AI Introduction', 'page': 1, 'topic': 'AI'}, page_content='\\n        Artificial Intelligence (AI) is the simulation of human intelligence in machines.\\n        These systems are designed to think like humans and mimic their actions.\\n        AI can be categorized into narrow AI and general AI.\\n        '),\n",
              " Document(metadata={'source': 'ML Basics', 'page': 1, 'topic': 'ML'}, page_content='\\n        Machine Learning is a subset of AI that enables systems to learn from data.\\n        Instead of being explicitly programmed, ML algorithms find patterns in data.\\n        Common types include supervised, unsupervised, and reinforcement learning.\\n        '),\n",
              " Document(metadata={'source': 'Deep Learning', 'page': 1, 'topic': 'DL'}, page_content='\\n        Deep Learning is a subset of machine learning based on artificial neural networks.\\n        It uses multiple layers to progressively extract higher-level features from raw input.\\n        Deep learning has revolutionized computer vision, NLP, and speech recognition.\\n        '),\n",
              " Document(metadata={'source': 'NLP Overview', 'page': 1, 'topic': 'NLP'}, page_content='\\n        Natural Language Processing (NLP) is a branch of AI that helps computers understand human language.\\n        It combines computational linguistics with machine learning and deep learning models.\\n        Applications include chatbots, translation, sentiment analysis, and text summarization.\\n        ')]"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_documents = [\n",
        "    Document(\n",
        "        page_content=\"\"\"\n",
        "        Artificial Intelligence (AI) is the simulation of human intelligence in machines.\n",
        "        These systems are designed to think like humans and mimic their actions.\n",
        "        AI can be categorized into narrow AI and general AI.\n",
        "        \"\"\",\n",
        "        metadata={\"source\": \"AI Introduction\", \"page\": 1, \"topic\": \"AI\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"\"\"\n",
        "        Machine Learning is a subset of AI that enables systems to learn from data.\n",
        "        Instead of being explicitly programmed, ML algorithms find patterns in data.\n",
        "        Common types include supervised, unsupervised, and reinforcement learning.\n",
        "        \"\"\",\n",
        "        metadata={\"source\": \"ML Basics\", \"page\": 1, \"topic\": \"ML\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"\"\"\n",
        "        Deep Learning is a subset of machine learning based on artificial neural networks.\n",
        "        It uses multiple layers to progressively extract higher-level features from raw input.\n",
        "        Deep learning has revolutionized computer vision, NLP, and speech recognition.\n",
        "        \"\"\",\n",
        "        metadata={\"source\": \"Deep Learning\", \"page\": 1, \"topic\": \"DL\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"\"\"\n",
        "        Natural Language Processing (NLP) is a branch of AI that helps computers understand human language.\n",
        "        It combines computational linguistics with machine learning and deep learning models.\n",
        "        Applications include chatbots, translation, sentiment analysis, and text summarization.\n",
        "        \"\"\",\n",
        "        metadata={\"source\": \"NLP Overview\", \"page\": 1, \"topic\": \"NLP\"}\n",
        "    )\n",
        "]\n",
        "\n",
        "sample_documents"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b069cfa",
      "metadata": {},
      "source": [
        "Step 2 : Split the text using a text splitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "e65f3c90",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Do text splitting\n",
        "# create template\n",
        "\n",
        "text_split = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 500,\n",
        "    chunk_overlap = 50, # 10% of text\n",
        "    length_function= len,\n",
        "    separators= [\" \", \"\", \"\\n\", \"\\n\\n\"]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "c2b44f3a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Artificial Intelligence (AI) is the simulation of human intelligence in machines.\n",
            "        These systems are designed to think like humans and mimic their actions.\n",
            "        AI can be categorized into narrow AI and general AI.\n",
            "Machine Learning is a subset of AI that enables systems to learn from data.\n",
            "        Instead of being explicitly programmed, ML algorithms find patterns in data.\n",
            "        Common types include supervised, unsupervised, and reinforcement learning.\n",
            "Deep Learning is a subset of machine learning based on artificial neural networks.\n",
            "        It uses multiple layers to progressively extract higher-level features from raw input.\n",
            "        Deep learning has revolutionized computer vision, NLP, and speech recognition.\n"
          ]
        }
      ],
      "source": [
        "# chunks\n",
        "chunks = text_split.split_documents(sample_documents)\n",
        "print(chunks[0].page_content)\n",
        "print(chunks[1].page_content)\n",
        "print(chunks[2].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6a6e9b8",
      "metadata": {},
      "source": [
        "Step : 3 Load the embedding model and create the embeddings of chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "dbd60fb7",
      "metadata": {},
      "outputs": [],
      "source": [
        "Embeddings = HuggingFaceEmbeddings(\n",
        "\tmodel_name = \"sentence-transformers/all-MiniLM-L6-v2\" )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "879ac9f0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.03653930127620697, -0.015164414420723915, 0.016432441771030426, 0.010568802244961262, 0.006010616198182106, -0.01847323216497898, 0.08546523004770279, 0.020968416705727577, 0.027815338224172592, 0.012431556358933449, -0.029376475140452385, -0.031135255470871925, 0.03491252288222313, -0.01815079152584076, -0.06498481333255768, 0.05168246105313301, -0.019606152549386024, -0.015734178945422173, -0.13371680676937103, -0.09645994007587433, -0.025471778586506844, -0.0014895368367433548, -0.006349359638988972, -0.02582070417702198, -0.027371758595108986, 0.12269002944231033, -0.007792471442371607, -0.03852272033691406, 0.014383504167199135, -0.0921841710805893, 0.008695729076862335, 0.0026133896317332983, 0.0910346731543541, -0.03031357377767563, -0.09604643285274506, 0.022288983687758446, -0.0902431309223175, -0.0329473614692688, 0.07158324867486954, -0.00889309961348772, -0.025708917528390884, -0.0791395977139473, 0.014530429616570473, -0.07420433312654495, 0.08045005798339844, 0.07804077863693237, -0.012956981547176838, 0.01989704556763172, 0.011450368911027908, 0.051634252071380615, -0.12571601569652557, 0.011675057001411915, -0.0463065467774868, 0.003381341928616166, 0.005173479672521353, 0.0281841903924942, 0.023271532729268074, 0.004088627174496651, 0.008011875674128532, -0.017078479751944542, 0.07944966107606888, -0.054664045572280884, 0.02551382966339588, 0.033813681453466415, 0.09233347326517105, 0.022148815914988518, -0.01819867268204689, 0.003242896869778633, -0.04002800211310387, -0.03808026388287544, 0.05245411768555641, 0.06670206040143967, -0.02631763368844986, 0.023634588345885277, 0.06188133358955383, -0.026365976780653, 0.0406007282435894, -0.038859523832798004, 0.1213383600115776, -0.04354514554142952, -0.011664088815450668, -0.01505763828754425, -0.03972955793142319, 0.06364047527313232, 0.004621610511094332, 0.007112923078238964, 0.01947830803692341, 0.004022035747766495, 0.04912211745977402, 0.05309614539146423, -0.03476697579026222, -0.057222481817007065, 0.06325118243694305, 0.0004573553742375225, 0.03859061747789383, 0.07343211770057678, -0.02629563957452774, -0.11324044317007065, -0.06495118141174316, 0.20607665181159973, -0.036265287548303604, 0.029907554388046265, -0.05536351725459099, 0.00876740925014019, -0.02121802233159542, 0.008762344717979431, 0.028472883626818657, -0.03460250794887543, 0.04979711025953293, -0.01885385252535343, -0.043652813881635666, -0.02558564767241478, 0.017332717776298523, -0.01112927496433258, 0.03276684135198593, 0.03506525605916977, 0.054944053292274475, 0.10390875488519669, 0.04061219096183777, 0.021712426096200943, -0.02442540042102337, -0.005160645116120577, -0.009341892786324024, 0.10581015050411224, 0.04529649391770363, -0.03663651645183563, -0.04464999958872795, -5.240089697078807e-33, -0.04903072863817215, -0.04560502991080284, 0.06606082618236542, 0.0015987895894795656, 0.023370295763015747, -0.03394041582942009, -0.020720111206173897, -0.02059014141559601, -0.03648071363568306, -0.010393086820840836, -0.10783457010984421, 0.01680215634405613, -0.07954582571983337, 0.04248005896806717, 0.13682305812835693, 0.010941176675260067, 0.00817004032433033, 0.030376331880688667, -0.06491046398878098, -0.007083632983267307, 0.028803102672100067, -0.035360950976610184, 0.0006858219276182353, -0.004703294485807419, -0.02408628538250923, 0.01617317833006382, 0.024679288268089294, -0.046101391315460205, 0.0454576276242733, 0.0008296648738905787, -0.003055404406040907, 0.0738888680934906, -0.054778944700956345, 0.0063984589651227, -0.010182932950556278, -0.013622526079416275, -0.025771547108888626, -0.018861854448914528, 0.01854046620428562, 0.07305724918842316, -0.034512538462877274, 0.02527776174247265, 0.00011160262511111796, 0.010052183642983437, -0.01425939705222845, -0.001591758686117828, 0.04002228006720543, -0.007197454571723938, -0.014384266920387745, -0.013920856639742851, -0.03563574329018593, 0.036473095417022705, 0.00893572997301817, -0.05683498829603195, 0.0535946823656559, -0.006161470897495747, -0.02172144129872322, 0.03370979428291321, -0.023625945672392845, -0.020359989255666733, 0.030925001949071884, 0.07569505274295807, -0.02297932282090187, 0.11616429686546326, -0.013501111418008804, 0.04918878898024559, 0.010986263863742352, 0.027952013537287712, 0.1211387887597084, 0.01650645211338997, -0.05092446133494377, -0.02870367094874382, 0.03939107805490494, 0.00595941161736846, -0.060958243906497955, 0.008872097358107567, -0.01463044248521328, -0.0711837187409401, -0.0076596541330218315, -0.0735979676246643, -0.1155097484588623, -0.013440397568047047, -0.04058428481221199, 0.00040523114148527384, 0.03743283450603485, -0.03617321699857712, -0.026406606659293175, -0.03851734846830368, 0.01877940446138382, -0.010150919668376446, -0.08086317032575607, 0.011855143122375011, -0.022952010855078697, 0.05883051082491875, -0.07994714379310608, 4.626795356004449e-33, -0.07962004840373993, -0.039513975381851196, -0.06382588297128677, 0.08893606066703796, -0.003736269660294056, -0.016144204884767532, -0.017867183312773705, -0.04251456633210182, 0.02442728728055954, 0.06664494425058365, -0.057895928621292114, -0.0423295833170414, 0.013483446091413498, 0.04562930762767792, 0.006878717336803675, -0.006714733317494392, 0.014821731485426426, -0.03707456961274147, -0.008778910152614117, 0.027316104620695114, -0.023431487381458282, 0.022865233942866325, -0.03276347741484642, -0.06674020737409592, -0.015621491707861423, 0.09837546944618225, -0.022562244907021523, 0.05578989163041115, -0.027223344892263412, 0.023653991520404816, 0.02509123831987381, -0.05378689989447594, -0.045490946620702744, 0.039963532239198685, 0.010178140364587307, 0.09332842379808426, 0.05655759200453758, -0.05569130927324295, -0.04962644353508949, 0.003936979919672012, 0.052554901689291, -0.03237330913543701, -0.05560151860117912, 0.09626691043376923, -0.037710100412368774, -0.0018547538202255964, -0.04098806157708168, 0.09643058478832245, -0.0009848824702203274, -0.021389655768871307, -0.04590706527233124, 0.016152795404195786, -0.0592200830578804, -0.0814569890499115, -0.10162124037742615, 0.002445462392643094, -0.01473918091505766, 0.014749257825314999, 0.0077284243889153, 0.04645295441150665, -0.012513836845755577, -0.006437147967517376, -0.0182336438447237, 0.042206380516290665, -0.08553377538919449, 0.04589942470192909, 0.02183121256530285, 0.035154566168785095, 0.0015752724139019847, -0.03905205428600311, 0.13990838825702667, 0.01811692677438259, -0.027118153870105743, 0.07361289113759995, -0.035381484776735306, 0.0038902899250388145, -0.0952819362282753, 0.009677501395344734, -0.004546663723886013, -0.05977969244122505, -0.05584699288010597, -0.08561266213655472, -0.006143816746771336, 0.0746932402253151, -0.028714315965771675, 0.08817896246910095, 0.012425342574715614, -0.03300655633211136, -0.028493564575910568, 0.028219277039170265, -0.0009965953649953008, 0.049375634640455246, 0.0024041191209107637, 0.0009696007473394275, -0.1360940933227539, -1.2270175098194613e-08, -0.015120250172913074, -0.018518701195716858, 0.10543893277645111, 0.006514136679470539, 0.06480391323566437, 0.022934284061193466, -0.06322947144508362, 0.005378750618547201, -0.011222903616726398, -0.02695935219526291, -0.005579792894423008, -0.02042907476425171, 0.08938045799732208, 0.031703416258096695, 0.07528702169656754, -0.0037162660155445337, -0.025884386152029037, 0.021603496745228767, -0.0085216723382473, -0.004489760380238295, 0.10893264412879944, -0.001388206030242145, -0.04064280912280083, 0.008054782636463642, 0.012936649844050407, -0.06289547681808472, -0.0034926605876535177, 0.03347349911928177, -0.049912694841623306, 0.11565354466438293, -0.003107016906142235, 0.10181651264429092, 0.05068749934434891, -0.009205094538629055, 0.06699430197477341, 0.056775741279125214, 0.013960146345198154, -0.047010377049446106, -0.042099203914403915, -0.02042977698147297, -0.016778377816081047, 0.09026879817247391, 0.009978685528039932, -0.08400097489356995, 0.10684642940759659, 0.004483684431761503, -0.006322795059531927, -0.1313309669494629, 0.07453564554452896, -0.052683472633361816, -0.01186329685151577, 0.0022889086976647377, 0.03824467584490776, 0.12563952803611755, 0.11970926076173782, -0.009724841453135014, 0.011950586922466755, -0.03378887102007866, -0.03487558290362358, 0.0892937183380127, 0.1176525428891182, 0.049785397946834564, 0.04860146343708038, -0.062488920986652374]\n"
          ]
        }
      ],
      "source": [
        "q1 = \"This is AKASH\"\n",
        "q1_embeddings = Embeddings.embed_query(q1)\n",
        "q1_embeddings\n",
        "\n",
        "\n",
        "# check on the document\n",
        "document_query = [\"AI\", \"MachineLearning\", \"Deep Learning\"]\n",
        "doc_embeddings = Embeddings.embed_documents(document_query)\n",
        "print(doc_embeddings[0]) # provide embeddings of AI"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2af119af",
      "metadata": {},
      "source": [
        "Step 4 : Function of Cosine Similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "689ecd7b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def cosine_similarity(text1, text2) :\n",
        "    vector1 = np.array(Embeddings.embed_query(text1))\n",
        "    vector2 = np.array(Embeddings.embed_query(text2))\n",
        "\n",
        "    # calculate similarity score\n",
        "\n",
        "    dot_prod = np.dot(vector1, vector2)\n",
        "    n1= np.linalg.norm(vector1)\n",
        "    n2= np.linalg.norm(vector2)\n",
        "\n",
        "    return dot_prod/(n1*n2)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "5d378d74",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI vs Artificial Intelligence : 0.590\n",
            "AI vs Pizza : 0.257\n"
          ]
        }
      ],
      "source": [
        "# Test similarity  score\n",
        "print(f\"AI vs Artificial Intelligence : {cosine_similarity(\"AI\",\"Arificial Intelligence\"):.3f}\")\n",
        "print(f\"AI vs Pizza : {cosine_similarity(\"AI\",\"Pizza\"):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da92e766",
      "metadata": {},
      "source": [
        "Step 5 : Create Vector Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "d9d61c27",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector store created with 4 vectors\n"
          ]
        }
      ],
      "source": [
        "vectorstore = FAISS.from_documents(\n",
        "    documents= chunks,\n",
        "    embedding = Embeddings )\n",
        "\n",
        "print(f\"Vector store created with {vectorstore.index.ntotal} vectors\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "95809cd7",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langchain_community.vectorstores.faiss.FAISS at 0x30b18f920>"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorstore"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdc0c86a",
      "metadata": {},
      "source": [
        "Saving and Loading the vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "db30679a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# save vector store for later use\n",
        "vectorstore.save_local(\"faiss_index\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "cd2212ff",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded vector store contains : 4 vectors\n"
          ]
        }
      ],
      "source": [
        "#load_vector\n",
        "loaded_vectorstore = FAISS.load_local(\n",
        "    \"faiss_index\",\n",
        "    Embeddings,\n",
        "    allow_dangerous_deserialization= True\n",
        ")\n",
        "\n",
        "print(f\"Loaded vector store contains : {loaded_vectorstore.index.ntotal} vectors\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "728b5159",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "9d3b5d7d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deep Learning is a subset of machine learning based on artificial neural networks.\n",
            "        It uses multiple layers to progressively extract higher-level features from raw input.\n",
            "        Deep learning has revolutionized computer vision, NLP, and speech recognition.\n",
            "Machine Learning is a subset of AI that enables systems to learn from data.\n",
            "        Instead of being explicitly programmed, ML algorithms find patterns in data.\n",
            "        Common types include supervised, unsupervised, and reinforcement learning.\n"
          ]
        }
      ],
      "source": [
        "## Similarity search - In Built function \n",
        "\n",
        "query = \"what is deep learning\"\n",
        "result = vectorstore.similarity_search(query, k=3)\n",
        "print(result[0].page_content)\n",
        "print(result[1].page_content)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "17e59f2a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Source : Deep Learning\n",
            "Content : Deep Learning is a subset of machine learning based on artificial neural networks.\n",
            "        It uses multiple layers to progressively extract higher-level features from raw input.\n",
            "        Deep learning \n",
            "2. Source : ML Basics\n",
            "Content : Machine Learning is a subset of AI that enables systems to learn from data.\n",
            "        Instead of being explicitly programmed, ML algorithms find patterns in data.\n",
            "        Common types include supervised\n",
            "3. Source : NLP Overview\n",
            "Content : Natural Language Processing (NLP) is a branch of AI that helps computers understand human language.\n",
            "        It combines computational linguistics with machine learning and deep learning models.\n",
            "      \n"
          ]
        }
      ],
      "source": [
        "# Now the top 3 answers are stored in result-it's just an array -> iterate it to check the responses\n",
        "\n",
        "for i, doc in enumerate(result) :\n",
        "    print(f\"{i+1}. Source : {doc.metadata['source']}\")\n",
        "    print(f\"Content : {doc.page_content[:200]}\")\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "7159e302",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(Document(id='0c91efe6-4e75-40f7-a1ef-4a0d11bbb7a2', metadata={'source': 'Deep Learning', 'page': 1, 'topic': 'DL'}, page_content='Deep Learning is a subset of machine learning based on artificial neural networks.\\n        It uses multiple layers to progressively extract higher-level features from raw input.\\n        Deep learning has revolutionized computer vision, NLP, and speech recognition.'), np.float32(0.34321663))\n",
            "<class 'tuple'>\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "# similarit search with score\n",
        "results_with_score = vectorstore.similarity_search_with_score(query, k=3)\n",
        "print(results_with_score[0])\n",
        "print(type(results_with_score[0]))\n",
        "print(len(results_with_score[0])) # first doc, second element is score \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "ec41acde",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score : 0.343\n",
            "Source : Deep Learning\n",
            "Content preview : Deep Learning is a subset of machine learning based on artificial neural networks.\n",
            "        It uses m\n",
            "Score : 1.090\n",
            "Source : ML Basics\n",
            "Content preview : Machine Learning is a subset of AI that enables systems to learn from data.\n",
            "        Instead of being\n",
            "Score : 1.154\n",
            "Source : NLP Overview\n",
            "Content preview : Natural Language Processing (NLP) is a branch of AI that helps computers understand human language.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for doc, score in results_with_score :\n",
        "    print(f\"Score : {score:.3f}\")\n",
        "    print(f\"Source : {doc.metadata['source']}\")\n",
        "    print(f\"Content preview : {doc.page_content[:100]}\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "fdde5d25",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number  : 1\n",
            "Name : Akash\n",
            "Number  : 2\n",
            "Name : Ashirwad\n",
            "Number  : 10\n",
            "Name : Bhim Singh\n"
          ]
        }
      ],
      "source": [
        "\n",
        "list1 = [(\"Akash\" , 1), (\"Ashirwad\" , 2), (\"Bhim Singh\" , 10)]\n",
        "\n",
        "for name, number in list1 :\n",
        "    print(f\"Number  : {number}\")\n",
        "    print(f\"Name : {name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "7bb58a1b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(id='d6b160f5-f55b-49d2-9500-4a9e937107e4', metadata={'source': 'ML Basics', 'page': 1, 'topic': 'ML'}, page_content='Machine Learning is a subset of AI that enables systems to learn from data.\\n        Instead of being explicitly programmed, ML algorithms find patterns in data.\\n        Common types include supervised, unsupervised, and reinforcement learning.')]\n"
          ]
        }
      ],
      "source": [
        "## Search with Metadata Filtering :\n",
        "filter_dict = {\"topic\" : \"ML\"}\n",
        "\n",
        "filtered_result = vectorstore.similarity_search(query, k=3, filter = filter_dict)\n",
        "print(filtered_result) # it will only return 1, coz ML is only in one metadata\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "a77a0db4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Using Anthropic LLM for RAG System\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "\n",
        "llm = ChatAnthropic(\n",
        "    model = \"claude-haiku-4-5-20251001\",\n",
        "    temperature= 0.7,\n",
        "    api_key=os.getenv(\"claudeAPI\") \n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "8a5fba87",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'langchain_core.messages.ai.AIMessage'>\n",
            "content=\"Hey! Everything's going well, thanks for asking! I'm doing good and ready to chat.\\n\\nHow about you? What's on your mind today?\" additional_kwargs={} response_metadata={'id': 'msg_01RTc9QDSLqySmmAmtj6XwTN', 'model': 'claude-haiku-4-5-20251001', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 17, 'output_tokens': 35, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-haiku-4-5-20251001'} id='run--0a9871d3-6cba-41e8-a94c-58d0bf85c564-0' usage_metadata={'input_tokens': 17, 'output_tokens': 35, 'total_tokens': 52, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}}\n"
          ]
        }
      ],
      "source": [
        "output = llm.invoke(\"Hey Claude, How is everything goin ? \")\n",
        "print(type(output))\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f76f541b",
      "metadata": {},
      "source": [
        "### Simple RAG Chain Using LCEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "2268cf94",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "simple_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\" \n",
        "    Answer the question based only on the following context\n",
        "    Context : {context}    \n",
        "    \n",
        "    Question : {question}\n",
        "\n",
        "    Answer : \n",
        "    \"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e13bab9d",
      "metadata": {},
      "source": [
        "- Next Step\n",
        "- Convert Vector Store to Retriever : \n",
        "    it allows your application to store the embeddings and fetch the most relevant document for a given query\n",
        "    \n",
        "User Query\n",
        "   ↓\n",
        "Retriever\n",
        "   ↓\n",
        "Vector Store (similarity search)\n",
        "   ↓\n",
        "Relevant Documents\n",
        "   ↓\n",
        "LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "414b8c98",
      "metadata": {},
      "source": [
        "### Retriever - Provide an interface for the queries and returns the Top K results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "456cc7a4",
      "metadata": {},
      "outputs": [],
      "source": [
        "retriever = vectorstore.as_retriever(\n",
        "            search_type= \"similarity\",\n",
        "            search_kwargs = {\"k\":3}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "2dd50772",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x30b18f920>, search_kwargs={'k': 3})"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "82a044d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Format the document for prompt\n",
        "\n",
        "from typing import List\n",
        "def format_docs (docs : List[Document]) -> str :\n",
        "    \"\"\"Format document for insertion into prompt \"\"\"\n",
        "    formatted = []\n",
        "    \n",
        "    for i, doc in enumerate(docs) :\n",
        "        source = doc.metadata.get('source', 'unknown')\n",
        "        formatted.append(f\"Document  {i+1} (Source : {source}) : \\n {doc.page_content}\")\n",
        "    return \"\\n\\n\".join(formatted)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e5aae97",
      "metadata": {},
      "source": [
        "#### Create the RAG pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c3b9c15",
      "metadata": {},
      "source": [
        "1. Format Prompt, question -> simple_prompt\n",
        "2. simple_prompt -> LLM\n",
        "3. LLM -> output "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "ca033d7a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{\n",
              "  context: VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x30b18f920>, search_kwargs={'k': 3})\n",
              "           | RunnableLambda(format_docs),\n",
              "  question: RunnablePassthrough()\n",
              "}\n",
              "| ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=' \\n    Answer the question based only on the following context\\n    Context : {context}    \\n\\n    Question : {question}\\n\\n    Answer : \\n    '), additional_kwargs={})])\n",
              "| ChatAnthropic(model='claude-haiku-4-5-20251001', temperature=0.7, anthropic_api_url='https://api.anthropic.com', anthropic_api_key=SecretStr('**********'), model_kwargs={})\n",
              "| StrOutputParser()"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# RunnablePassthrough - move from one step to another in the pipeline\n",
        "# StrOutputParser() - prints the output of LLM\n",
        "\n",
        "\n",
        "# simple_rag_chain.invoke(question)\n",
        "# cause of RunnablePassthrough when we invoke the chain we can put the question and it will operate\n",
        "\n",
        "\n",
        "simple_rag_chain = (\n",
        "    {\"context\" : retriever | format_docs, \"question\" : RunnablePassthrough()}\n",
        "    | simple_prompt\n",
        "    | llm \n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "simple_rag_chain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26ab50c7",
      "metadata": {},
      "source": [
        "### Conversational Rag Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "087775e5",
      "metadata": {},
      "outputs": [],
      "source": [
        "conversational_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful AI assitant. Use the provided context to answer quesstions.\"),\n",
        "    (\"placeholder\", \"{chat_history}\"),\n",
        "    (\"human\", \"context : {context}\\n\\n Question : {input}\")\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ec9d317",
      "metadata": {},
      "source": [
        "Define the functions for creational_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "aaa7fcde",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RunnableAssign(mapper={\n",
              "  context: RunnableLambda(lambda x: format_docs(retriever.invoke(x['input'])))\n",
              "})\n",
              "| ChatPromptTemplate(input_variables=['context', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x10afa7f60>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful AI assitant. Use the provided context to answer quesstions.'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template='context : {context}\\n\\n Question : {input}'), additional_kwargs={})])\n",
              "| ChatAnthropic(model='claude-haiku-4-5-20251001', temperature=0.7, anthropic_api_url='https://api.anthropic.com', anthropic_api_key=SecretStr('**********'), model_kwargs={})\n",
              "| StrOutputParser()"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# what does lambda x do ? \n",
        "def create_conversational_rag():\n",
        "    \"\"\" Create a conversational RAG Chain with memory\"\"\"\n",
        "    return (\n",
        "        RunnablePassthrough.assign(\n",
        "            context = lambda x : format_docs(retriever.invoke(x['input']))\n",
        "        )\n",
        "        | conversational_prompt\n",
        "        |llm\n",
        "        |StrOutputParser()\n",
        "    )\n",
        "\n",
        "conversational_rag = create_conversational_rag()\n",
        "conversational_rag"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96ab8242",
      "metadata": {},
      "source": [
        "Streaming Rag Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "4766baab",
      "metadata": {},
      "outputs": [],
      "source": [
        "streaming_rag_chain = (\n",
        "    {\"context\" : retriever | format_docs, \"question\" : RunnablePassthrough()}\n",
        "    | simple_prompt\n",
        "    | llm\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72ab65b1",
      "metadata": {},
      "source": [
        "- Test for different chain types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "id": "ec6acb47",
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_rag_chains(question : str):\n",
        "    \"\"\" Test all RAG chain variants \"\"\"\n",
        "    print(f\"Question : {question}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # 1. simple rag\n",
        "    print(\"\\n 1.Simple Rag Chain\")\n",
        "    answer = simple_rag_chain.invoke(question)\n",
        "    print(f\"Answer : {answer}\")\n",
        "    \n",
        "\n",
        "    print(\"\\n 2. Streaming RAG\")\n",
        "    print(\"Answer : \", end = \" \", flush= True)\n",
        "    \n",
        "    for chunk in streaming_rag_chain.stream(question):\n",
        "        print(chunk.content, end = \"\", flush= True)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "id": "6c449dbd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question : what is the difference b/w AI and Machine Learning\n",
            "================================================================================\n",
            "\n",
            " 1.Simple Rag Chain\n",
            "Answer : # Difference between AI and Machine Learning\n",
            "\n",
            "Based on the provided context:\n",
            "\n",
            "**Artificial Intelligence (AI):**\n",
            "- The simulation of human intelligence in machines\n",
            "- Systems designed to think like humans and mimic their actions\n",
            "- Can be categorized into narrow AI and general AI\n",
            "\n",
            "**Machine Learning (ML):**\n",
            "- A subset of AI that enables systems to learn from data\n",
            "- Instead of being explicitly programmed, ML algorithms find patterns in data\n",
            "- Common types include supervised, unsupervised, and reinforcement learning\n",
            "\n",
            "**Key Difference:**\n",
            "The main difference is that **AI is the broader field** focused on simulating human intelligence, while **Machine Learning is a specific subset of AI** that accomplishes this through algorithms that learn patterns from data, rather than through explicit programming.\n",
            "\n",
            " 2. Streaming RAG\n",
            "Answer :  Based on the provided context, here are the key differences between AI and Machine Learning:\n",
            "\n",
            "**Artificial Intelligence (AI):**\n",
            "- AI is the simulation of human intelligence in machines\n",
            "- These systems are designed to think like humans and mimic their actions\n",
            "- AI can be categorized into narrow AI and general AI\n",
            "\n",
            "**Machine Learning (ML):**\n",
            "- Machine Learning is a **subset of AI** that enables systems to learn from data\n",
            "- Instead of being explicitly programmed, ML algorithms find patterns in data\n",
            "- Common types include supervised, unsupervised, and reinforcement learning\n",
            "\n",
            "**Key Difference:**\n",
            "The main distinction is that AI is the broader field focused on simulating human intelligence, while Machine Learning is a specific approach within AI that focuses on systems learning from data and identifying patterns, rather than being explicitly programmed.\n"
          ]
        }
      ],
      "source": [
        "test_rag_chains(\"what is the difference b/w AI and Machine Learning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64e1a995",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with multiple questions\n",
        "\n",
        "test_question = [\n",
        "    \"what is the diffrence b/w AI and Machine Learning\",\n",
        "    \"Explain deep learning in simple terms\",\n",
        "    \"How does NLP work ?\"\n",
        "]\n",
        "\n",
        "for question in test_question:\n",
        "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "    test_rag_chains(question)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc5e1519",
      "metadata": {},
      "source": [
        "Conversational Rag Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "fe5e8f7a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is machine learning\n",
            "# What is Machine Learning?\n",
            "\n",
            "Based on the provided context, **Machine Learning (ML) is a subset of Artificial Intelligence that enables systems to learn from data.**\n",
            "\n",
            "## Key Characteristics:\n",
            "\n",
            "- **Learning from Data**: Instead of being explicitly programmed with instructions, ML algorithms automatically find patterns in data\n",
            "- **Types of ML**: Common approaches include:\n",
            "  - Supervised learning\n",
            "  - Unsupervised learning\n",
            "  - Reinforcement learning\n",
            "\n",
            "In essence, Machine Learning allows computers to improve their performance on tasks by learning from examples and patterns in data, rather than relying solely on pre-programmed rules.\n"
          ]
        }
      ],
      "source": [
        "chat_history = []\n",
        "\n",
        "q1= \"What is machine learning\"\n",
        "a1 = conversational_rag.invoke(\n",
        "   {\n",
        "    \"input\" : q1, \n",
        "    \"chat_history\" : chat_history\n",
        "   } \n",
        ")\n",
        "\n",
        "print(q1)\n",
        "print(a1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7fcadd3",
      "metadata": {},
      "outputs": [],
      "source": [
        "chat_history.extend(\n",
        "    [\n",
        "        HumanMessage(content=q1),\n",
        "        AIMessage(content = a1)\n",
        "\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8503c912",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
