{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cad244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akashdeepsangwan/Desktop/Code/GenAI/RAG/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9f7a017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the document - Template of PyMuP\n",
    "\n",
    "docs = PyMuPDFLoader(\"/Users/akashdeepsangwan/Desktop/Code/GenAI/RAG/Can AI Build Systems (1).pdf\").load()\n",
    "type(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbcc53e",
   "metadata": {},
   "source": [
    "#### PDF Extracted provide an array, Each element is a whole page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "654a84e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our methodology aims to provide more structured, end-to- end\n",
      "support for architects, ranging from early analysis to design-\n",
      "level detailing.\n",
      "III. METHODOLOGY\n",
      "We applied various prompt engineering techniques to eval-\n",
      "uate the performance of different Large Language Models\n",
      "(LLMs) in generating architecture of software systems given\n",
      "their textual descriptions in natural langauge. Specifically,\n",
      "we benchmarked three prominent LLMs under each of these\n",
      "prompting strategies: OpenAI o3, the latest reasoning-tuned\n",
      "successor to the GPT-4 family; Gemini 2.0 Gemini, Google’s\n",
      "latency-optimised variant of Gemini designed for rapid iter-\n",
      "ative calls; and Llama 4 Llama, Meta’s fourth-generation\n",
      "open-weight model fine-tuned for software-engineering tasks.\n",
      "These models are selected based on popularity and their\n",
      "wide applicability on software development tasks. We evaluate\n",
      "two complementary workflows for turning a natural-language\n",
      "system description into a PlantUML component diagram. We\n",
      "decided to use UML, particularly PlantUML for modeling due\n",
      "to a number of factors, such as available documentation, ease\n",
      "of use, tool support, and wide-scale adoption as a language\n",
      "to represent software systems [13]. This ubiquity also means\n",
      "contemporary LLMs have substantial prior exposure to UML\n",
      "outputs, which in practice reduces syntactic errors in generated\n",
      "diagrams.\n",
      "Single-Pass Generation:\n",
      "We first apply “Zero-shot”\n",
      "prompting [14], “In-context” learning [15] and “Chain-of-\n",
      "thought” prompting [16], which are well-established prompt-\n",
      "engineering strategies, requiring the model to infer a diagram\n",
      "without anyother external help, such as a dedicated knowledge\n",
      "base. In-context learning embeds relevant examples directly\n",
      "inside the prompt so that the model can align its output with\n",
      "previously observed patterns. Chain-of-though prompting\n",
      "instructs the model to generate step-by-step reasoning thereby\n",
      "fostering more transparent and decomposed generation. It\n",
      "has proven effective for complex queries that require multi-\n",
      "step solutions. All nine model-prompt combinations received\n",
      "identical inputs and produced PlantUML component diagrams\n",
      "that were subsequently parsed for evaluation in the following\n",
      "subsections.\n",
      "Two-Pass Iterative Refinement: Inspired by how human\n",
      "architects sketch a draft and then polish it, we evaluate a\n",
      "similar iterative refinement approach that has been previously\n",
      "explored in areas such as natural language translation [17],\n",
      "mathematical reasoning [18], and coding [19]. Concretely, we\n",
      "adopt a two-pass strategy consisting of two LLMs chained\n",
      "together. The first model is responsible for generating a\n",
      "preliminary output, which is subsequently passed to the second\n",
      "model to have its issues diagnosed and appropriately fixed\n",
      "to enhance overall quality and ensure correctness. In our\n",
      "domain, the first model may establish the overall structure\n",
      "of the software architecture, such as crucial components\n",
      "and connections, while the second one analyzes this initial\n",
      "response, identifying and rectifying missing or redundant\n",
      "interfaces, anti-patterns, confused module responsibilities, or\n",
      "other problems that could degrade the architecture. Because\n",
      "each of the nine model–prompt settings can serve in either\n",
      "the “drafter” or “refiner” role, we evaluate all 81 ordered\n",
      "pairs (9 × 9).\n",
      "Together, the single-pass and iterative experiments let us\n",
      "assess: (i) what levels of accuracy, compared to the intended\n",
      "architecture, the best model–prompt combination can reach\n",
      "on its own, and (ii) how much additional gain is unlocked\n",
      "when a second model is invited to critique and correct the\n",
      "initial design. This comparative analysis identifies methods\n",
      "that improve performance and assesses the strengths and\n",
      "limitations of current generative AI technology in generating\n",
      "software architecture from textual descriptions. The findings\n",
      "provide insights into the feasibility of employing generative\n",
      "models as co-pilots for a faster more reliable process of\n",
      "archtitecture generation.\n",
      "IV. EXPERIMENT\n",
      "A. Data and Baseline\n",
      "We began by mining public GitHub repositories with one\n",
      "or more of the following keywords: “microservices”, “event-\n",
      "driven”, “architecture”. The focus on microservices and\n",
      "event-driven architectures was due to the fact repositories that\n",
      "follow these architectures tend to document the components\n",
      "or services of their system in detail, which provides enough\n",
      "information for the LLM. Using GitHub Search, we queried\n",
      "repositories with such keywords. We filtered these repositories\n",
      "down to 25 repositories whose README files included at\n",
      "least brief description of the system and contained at least\n",
      "one diagram illustrating the system’s overall structure. This\n",
      "first pass eliminated more implementation specific repositories,\n",
      "leaving projects with enough narrative context to ground an\n",
      "architectural discussion.\n",
      "From that shortlist we selected two systems whose system\n",
      "description captured every salient feature or business capabil-\n",
      "ity, the supplied diagram depicts a high-level architecture and\n",
      "the domain logic is non-trivial. Choosing a pair of reasonably\n",
      "complex yet fully documented systems allows us to test\n",
      "whether LLMs can infer both breadth (all major components)\n",
      "and depth (domain-specific responsibilities).\n",
      "For each chosen repository we extracted textual description\n",
      "by stripping out implementation specific information such as\n",
      "language, framework, or container orchestration script and\n",
      "retained only sentences that describe functional and non\n",
      "functional requirements, domain entities, and inter-service\n",
      "interactions. Separately, we recreated the project’s original\n",
      "architecture diagram as a PlantUML component diagram,\n",
      "normalizing notation so that every baseline as well generated\n",
      "diagram shares the same semantic granularity (components\n",
      "and directed connectors). This baseline acts as the reference\n",
      "against which every LLM-generated diagram is compared.\n",
      "Because the baseline reflects the intended architecture as\n",
      "documented in the repository, it lets us gauge how effectively\n",
      "each model: (i) understands the developer’s intent embodied\n",
      "in the textual description, (ii) captures all domain-critical\n",
      "components and their relationships, and (iii) preserves—or\n"
     ]
    }
   ],
   "source": [
    "print((docs[2].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1532025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create chunks of this PDF\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 600,\n",
    "    chunk_overlap = 65,\n",
    "    length_function = len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70a2c18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of chunks 101\n"
     ]
    }
   ],
   "source": [
    "chunks = splitter.split_documents(docs)\n",
    "print(f\"No of chunks {len(chunks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "88d5d74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(chunks[1].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ca56e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tion cohesively. Despite being introduced only recently, Large\n",
      "Language Models (LLMs) have shown great potential in au-\n",
      "tomating low-level software engineering tasks, such as coding\n",
      "and test generation. However, the application of LLMs on high\n",
      "level cognitive tasks, such as architecture and design, has not\n",
      "been explored as much. To that end, this study evaluates the\n",
      "capability of LLMs—specifically Llama 4 Llama, Gemini 2.0\n",
      "Gemini, and OpenAI o3 in generating software architecture\n",
      "given unstructured textual requirements in natural language.\n"
     ]
    }
   ],
   "source": [
    "print(chunks[1].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80688f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1\n",
      "Can AI Build Systems? An Exploratory Study on\n",
      "Generating Software Architecture with LLMs\n",
      "Marios Foka...in shaping\n",
      "the quality, maintainability, and integrity of a software system,\n",
      "providing a blueprint that ensures that all components func-\n",
      "tion cohesively. Despite being introduced only recently, Large\n",
      "-------------------------------------------------------------------------\n",
      "Chunk 2\n",
      "tion cohesively. Despite being introduced only recently, Large\n",
      "Language Models (LLMs) have shown gre...his study evaluates the\n",
      "capability of LLMs—specifically Llama 4 Llama, Gemini 2.0\n",
      "Gemini, and OpenAI o3 in generating software architecture\n",
      "given unstructured textual requirements in natural language.\n",
      "-------------------------------------------------------------------------\n",
      "Chunk 3\n",
      "given unstructured textual requirements in natural language.\n",
      "We employ prompt engineering techniques..., akin to a\n",
      "human editing a preliminary draft for improvements. Our results\n",
      "indicate that state of the art models like OpenAI o3 and Gemini\n",
      "2.0 Gemini perform exceptionally well in identifying all the\n",
      "-------------------------------------------------------------------------\n",
      "Chunk 4\n",
      "2.0 Gemini perform exceptionally well in identifying all the\n",
      "domain concepts of the system and how t...e by using the correct\n",
      "architectural styles especially with Chain-of-Thought prompting,\n",
      "however Llama’s model do not infer the correct styles.\n",
      "Index Terms—software architecture, large language models,\n",
      "-------------------------------------------------------------------------\n",
      "Chunk 5\n",
      "Index Terms—software architecture, large language models,\n",
      "UML, software design, software requirement...le of software\n",
      "architecture extends beyond algorithms and data structures to\n",
      "include considerations such as system organization, control\n",
      "structures, data access protocols, scalability, and performance\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(5) :\n",
    "    print(f\"Chunk {i+1}\")\n",
    "    print(f\"{chunks[i].page_content[:100] + \"...\" + chunks[i].page_content[len(chunks[i].page_content)-200:] }\")\n",
    "    print(\"-------------------------------------------------------------------------\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5b2350",
   "metadata": {},
   "source": [
    "### Has Good Amount of OverLap - Task Done\n",
    "\n",
    "- Next : Will apply semantic chunking in Chunking process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "87b4d05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9710fea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "Embeddings= HuggingFaceEmbeddings(\n",
    "    model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eeda4f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "sentences = [chunk.page_content for chunk in chunks]\n",
    "print(len(sentences)== len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fa926485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "253fcd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "# Convert the text into embeddings now\n",
    "doc_embeddings = Embeddings.embed_documents(sentences)\n",
    "print(len(doc_embeddings))\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd7bad8",
   "metadata": {},
   "source": [
    "Cosine similarity max is 1, when the angle b/w two vector is zero, means they overlap each other "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097aa156",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.7  # control chunk tightness\n",
    "new_chunks = []\n",
    "current_chunk=[sentences[0]]\n",
    "\n",
    "## Step 4: Semantic grouping based on threshold\n",
    "\n",
    "for i in range(1, len(sentences)):\n",
    "    sim = cosine_similarity(\n",
    "        [doc_embeddings[i - 1]],\n",
    "        [doc_embeddings[i]]\n",
    "    )[0][0]\n",
    "\n",
    "    if sim>=threshold:\n",
    "        current_chunk.append(sentences[i])\n",
    "    else:\n",
    "        new_chunks.append(\" \".join(current_chunk))\n",
    "        current_chunk=[sentences[i]]\n",
    "\n",
    "# Append the last chunk\n",
    "new_chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "# Output the chunks\n",
    "print(\" Semantic Chunks:\")\n",
    "for idx, chunk in enumerate(new_chunks):\n",
    "    print(f\"\\nChunk {idx+1}:\\n{new_chunks}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "916a58f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Chunk 5\n",
      "Index Terms—software architecture, large language models,\n",
      "UML, software design, software requirement\n",
      "******************************************\n",
      "Older Chunk 5\n",
      "Index Terms—software architecture, large language models,\n",
      "UML, software design, software requirement\n",
      "-----------------------------------------\n",
      "New Chunk 6\n",
      "These\n",
      "methodologies enable systematic development while main-\n",
      "taining intellectual control over syst\n",
      "******************************************\n",
      "Older Chunk 6\n",
      "structures, data access protocols, scalability, and performance\n",
      "optimization [1]. Architectural deci\n",
      "-----------------------------------------\n",
      "New Chunk 7\n",
      "software architects in their architectural design decisions and\n",
      "evaluation to reduce the time requir\n",
      "******************************************\n",
      "Older Chunk 7\n",
      "These\n",
      "methodologies enable systematic development while main-\n",
      "taining intellectual control over syst\n",
      "-----------------------------------------\n",
      "New Chunk 8\n",
      "even writing and debugging software code. The application of\n",
      "LLMs in software engineering spans mult\n",
      "******************************************\n",
      "Older Chunk 8\n",
      "software architects in their architectural design decisions and\n",
      "evaluation to reduce the time requir\n",
      "-----------------------------------------\n",
      "New Chunk 9\n",
      "To explore the effectiveness of LLMs in software archi-\n",
      "tecture generation, this study focuses on a \n",
      "******************************************\n",
      "Older Chunk 9\n",
      "even writing and debugging software code. The application of\n",
      "LLMs in software engineering spans mult\n",
      "-----------------------------------------\n",
      "New Chunk 10\n",
      "in-context, and chain-of-thought—with three state-of-the-art\n",
      "LLMs: OpenAI o31, Gemini 2.0 Flash2, an\n",
      "******************************************\n",
      "Older Chunk 10\n",
      "To explore the effectiveness of LLMs in software archi-\n",
      "tecture generation, this study focuses on a \n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(4,10) :\n",
    "    print(f\"New Chunk {i+1}\")\n",
    "    print(new_chunks[i][:100])\n",
    "    print(\"******************************************\")\n",
    "    print(f\"Older Chunk {i+1}\")\n",
    "    print(chunks[i].page_content[:100])\n",
    "\n",
    "    print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb70bf17",
   "metadata": {},
   "source": [
    "#### After Semantic chunking, the chunks got combined that's why the length of new_chunks is less than older chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "85b9eb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "print(len(new_chunks))\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6f5f0a",
   "metadata": {},
   "source": [
    "#### Next : Create the new embeddings of new_chunks and store them in the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "87ec8e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(new_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217c9efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    }
   ],
   "source": [
    "# this step can be skipped when using FAISS\n",
    "new_embeddings= Embeddings.embed_documents(new_chunks) # take array of strings as a input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4487291c",
   "metadata": {},
   "source": [
    "### Store the embeddings into a vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4e7df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "semantic_document=[\n",
    "    Document(\n",
    "        page_content = chunk_text,\n",
    "        metadata = {\n",
    "            'chunk_type' : 'semantic',\n",
    "            'source' : \"Can AI Build Systems (1).pdf\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    for chunk_text in new_chunks\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4098aca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "\n",
    "vector_store = FAISS.from_documents(\n",
    "    documents = semantic_document,\n",
    "    embedding = Embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1cc2f8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x360296000>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76cb5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
