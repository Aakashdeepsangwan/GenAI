{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c82aa064",
   "metadata": {},
   "source": [
    "### Building a Rag System with Langchain and ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314a7647",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8df57a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRetrieval-Augmented Generation (RAG) is a powerful technique that combines the capabilities of LLM with external knowlege retrieval.\\nwe will build a complete rag system using langchain, chromaDB, Hugging Face Embeddings\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Retrieval-Augmented Generation (RAG) is a powerful technique that combines the capabilities of LLM with external knowlege retrieval.\n",
    "we will build a complete rag system using langchain, chromaDB, Hugging Face Embeddings\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925a6dd5",
   "metadata": {},
   "source": [
    "- Loading of the Document\n",
    "- Document splitter\n",
    "- Create Chunk\n",
    "- Embeddings Model\n",
    "- Vector Store/Database\n",
    "- Semantic Search\n",
    "- Context Augmentation : Combine retrived chunk with query\n",
    "- Response Generation : LLM generates answer using context\n",
    "\n",
    "Benefits of RAG :\n",
    "- Reduce Hallucinations\n",
    "- Provides up-to-date information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbbae2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "# vectore stores\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "\n",
    "# Utility imports\n",
    "import numpy as np\n",
    "from typing import List \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f6f2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_docs = [\n",
    "    \"\"\"\n",
    "    Machine Learning Fundamentals\n",
    "    \n",
    "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
    "    and improve from experience without being explicitly programmed. There are three main \n",
    "    types of machine learning: supervised learning, unsupervised learning, and reinforcement \n",
    "    learning. Supervised learning uses labeled data to train models, while unsupervised \n",
    "    learning finds patterns in unlabeled data. Reinforcement learning learns through \n",
    "    interaction with an environment using rewards and penalties.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Deep Learning and Neural Networks\n",
    "    \n",
    "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
    "    These networks are inspired by the human brain and consist of layers of interconnected \n",
    "    nodes. Deep learning has revolutionized fields like computer vision, natural language \n",
    "    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \n",
    "    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \n",
    "    excel at sequential data processing.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Natural Language Processing (NLP)\n",
    "    \n",
    "    NLP is a field of AI that focuses on the interaction between computers and human language. \n",
    "    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \n",
    "    machine translation, and question answering. Modern NLP heavily relies on transformer \n",
    "    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \n",
    "    context and relationships between words in text.\n",
    "    \"\"\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3b02549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample document create in : /var/folders/58/7rk_l2gn3lv73f_nlj98yjgc0000gn/T/tmpuuhmaghy\n"
     ]
    }
   ],
   "source": [
    "## save sample documents to files\n",
    "import tempfile\n",
    "temp_dir=tempfile.mkdtemp()\n",
    "\n",
    "for i,doc in enumerate(sample_docs):\n",
    "    with open(f\"{temp_dir}/doc_{i}.txt\",\"w\") as f:\n",
    "        f.write(doc)\n",
    "\n",
    "print(f\"Sample document create in : {temp_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067e768f",
   "metadata": {},
   "source": [
    "### Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "456f47b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents\n",
      "\n",
      "First Document Preview\n",
      "\n",
      "    Deep Learning and Neural Networks\n",
      "\n",
      "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers..\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    temp_dir,\n",
    "    glob =\"*.txt\",\n",
    "    loader_cls = TextLoader,\n",
    "    loader_kwargs = {'encoding': 'utf-8'}\n",
    ")\n",
    "\n",
    "\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "print(f\"\\nFirst Document Preview\")\n",
    "print(documents[2].page_content[:200]+ \"..\")\n",
    "\n",
    "\n",
    "\n",
    "# we created a list of text and then converted that to a text file \n",
    "# loaded the data from text file as usual\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57d3179",
   "metadata": {},
   "source": [
    "### Chunking : Document Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5583031b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 7 chunks from 3\n",
      "Content Natural Language Processing (NLP)\n",
      "\n",
      "    NLP is a field of AI that focuses on the interaction between computers and human language. \n",
      "    Key tasks in NL ...\n",
      "Metadata : {'source': '/var/folders/58/7rk_l2gn3lv73f_nlj98yjgc0000gn/T/tmpuuhmaghy/doc_2.txt'}\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 50,\n",
    "    length_function = len,\n",
    "    separators = [\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "\n",
    "print(f\"Created {len(chunks)} chunks from {len(documents)}\")\n",
    "\n",
    "print(f\"Content {chunks[0].page_content[:150]} ...\")\n",
    "print(f\"Metadata : {chunks[0].metadata}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce4249d",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e38525a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "HF_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ef24375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/var/folders/58/7rk_l2gn3lv73f_nlj98yjgc0000gn/T/tmpuuhmaghy/doc_2.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.'),\n",
       " Document(metadata={'source': '/var/folders/58/7rk_l2gn3lv73f_nlj98yjgc0000gn/T/tmpuuhmaghy/doc_0.txt'}, page_content='Machine Learning Fundamentals'),\n",
       " Document(metadata={'source': '/var/folders/58/7rk_l2gn3lv73f_nlj98yjgc0000gn/T/tmpuuhmaghy/doc_0.txt'}, page_content='Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       " Document(metadata={'source': '/var/folders/58/7rk_l2gn3lv73f_nlj98yjgc0000gn/T/tmpuuhmaghy/doc_0.txt'}, page_content='interaction with an environment using rewards and penalties.'),\n",
       " Document(metadata={'source': '/var/folders/58/7rk_l2gn3lv73f_nlj98yjgc0000gn/T/tmpuuhmaghy/doc_1.txt'}, page_content='Deep Learning and Neural Networks'),\n",
       " Document(metadata={'source': '/var/folders/58/7rk_l2gn3lv73f_nlj98yjgc0000gn/T/tmpuuhmaghy/doc_1.txt'}, page_content='Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'),\n",
       " Document(metadata={'source': '/var/folders/58/7rk_l2gn3lv73f_nlj98yjgc0000gn/T/tmpuuhmaghy/doc_1.txt'}, page_content='excel at sequential data processing.')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e884e09f",
   "metadata": {},
   "source": [
    "### Store Embeddings into VectorStores : ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "89c6f4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created with 14 vectors\n",
      "Persisted to : ./chroma_db\n"
     ]
    }
   ],
   "source": [
    "# Create a ChromaDB Vector Store\n",
    "persist_directory = \"./chroma_db\"\n",
    "\n",
    "# Initialize ChromaDB with HuggingFace Embeddings\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents = chunks, # it should be an array\n",
    "    embedding = HF_embeddings, \n",
    "    persist_directory = persist_directory, # place where the vector stores are stored\n",
    "    collection_name = \"rag_collection\" # name of the vector store\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Vector store created with {vectorstore._collection.count()} vectors\")\n",
    "print(f\"Persisted to : {persist_directory}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be880cd",
   "metadata": {},
   "source": [
    "### Test Similarity Seach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "43d7ad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vector1, vector2):\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    normal_v1 = np.linalg.norm(vector1)\n",
    "    normal_v2 = np.linalg.norm(vector2)\n",
    "    similarity  = dot_product/ (normal_v1* normal_v2)\n",
    "    return similarity\n",
    "\n",
    "def semantic_search(query, documents, embeddings_model, top_k=3):\n",
    "    \"\"\" simple semantic search implementation \"\"\"\n",
    "\n",
    "    query_embedding = embeddings_model.embed_query(query)\n",
    "    doc_embedding = embeddings_model.embed_documents(documents)\n",
    "\n",
    "    # similarity score\n",
    "    \n",
    "    similarities = []\n",
    "\n",
    "    for i, doc_emb in enumerate(doc_embedding) :\n",
    "        similarity = cosine_similarity(query_embedding, doc_emb)\n",
    "        similarities.append((similarity, documents[i])) \n",
    "\n",
    "    # sort it by similarity\n",
    "    similarities.sort(reverse = True)\n",
    "    return similarities[ : top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb1b35b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/var/folders/58/7rk_l2gn3lv73f_nlj98yjgc0000gn/T/tmpuuhmaghy/doc_2.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.'),\n",
       " Document(metadata={'source': '/var/folders/58/7rk_l2gn3lv73f_nlj98yjgc0000gn/T/tmpuuhmaghy/doc_2.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.'),\n",
       " Document(metadata={'source': '/var/folders/58/7rk_l2gn3lv73f_nlj98yjgc0000gn/T/tmpuuhmaghy/doc_0.txt'}, page_content='Machine Learning Fundamentals')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what is NLP?\"\n",
    "similar_docs = vectorstore.similarity_search(query, k=3)\n",
    "similar_docs\n",
    "\n",
    "# When we ues the vector database or stores, the coversion from text to embeddings is automati"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd21759b",
   "metadata": {},
   "source": [
    "# 2. Understanding the similarity Score\n",
    "\n",
    "The similarity score represents how closely related a document chunk is to your query. The scoring depends on the distance metric used :\n",
    "\n",
    "Chroma default : Uses L2 distance(Euclidean distance)\n",
    "\n",
    "Lower Score = More similar (closer in vector shape)\n",
    "Score of 0 = identical vectors\n",
    "Typical range : 0 to 2 (but can be higher)\n",
    "\n",
    "Cosine Similarity (if configured)\n",
    "\n",
    "Higher Score = Mores similar\n",
    "Range : -1 to 1 (being indentical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b803a6ba",
   "metadata": {},
   "source": [
    "### Initalize LLM, RAG Chain, Prompt Template, Query the RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a9230b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf5c030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM (ChatAnthropic)\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "llm = ChatAnthropic(\n",
    "    model=\"claude-haiku-4-5-20251001\",  \n",
    "    temperature=0.7,\n",
    "    api_key=os.getenv(\"claudeAPI\") \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "03a098f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='# LLM Models\\n\\n**LLM** stands for **Large Language Model**. Here\\'s what you need to know:\\n\\n## What They Are\\nLLMs are AI systems trained on massive amounts of text data to understand and generate human language. They predict the next word in a sequence based on patterns learned during training.\\n\\n## Key Characteristics\\n- **Large scale**: Billions to trillions of parameters (internal variables)\\n- **Neural networks**: Built on deep learning architecture (transformers)\\n- **Pre-trained**: Trained on diverse internet text before being fine-tuned\\n- **Generative**: Can create new text, not just analyze it\\n\\n## Common Examples\\n- **ChatGPT** (OpenAI)\\n- **Claude** (Anthropic)\\n- **Gemini** (Google)\\n- **Llama** (Meta)\\n- **GPT-4** (OpenAI)\\n\\n## What They Can Do\\n✓ Answer questions  \\n✓ Write content  \\n✓ Translate languages  \\n✓ Code programming  \\n✓ Summarize text  \\n✓ Have conversations  \\n\\n## Limitations\\n✗ Can hallucinate (make up false information)  \\n✗ Have knowledge cutoff dates  \\n✗ Don\\'t truly \"understand\" like humans  \\n✗ Reflect biases in training data  \\n\\n## How They Work (Simply)\\nThey process text as tokens → analyze patterns → predict most likely next token → generate coherent responses\\n\\nWould you like me to explain any specific aspect in more detail?', additional_kwargs={}, response_metadata={'id': 'msg_01GUmhepWDucKVP8gWgqJrVt', 'model': 'claude-haiku-4-5-20251001', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 13, 'output_tokens': 351, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-haiku-4-5-20251001', 'model_provider': 'anthropic'}, id='lc_run--019b29a3-1146-7990-a026-7089a4b7e4dc-0', usage_metadata={'input_tokens': 13, 'output_tokens': 351, 'total_tokens': 364, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_response = llm.invoke(\"What's LLM Models\")\n",
    "test_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87ef404",
   "metadata": {},
   "source": [
    "### Modern RAG Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff5ad1",
   "metadata": {},
   "source": [
    "- Langchain moved to LCEL(LangChain Expression Language) as the primary way to build chains\n",
    "- LCEL uses the pipe(|) operator instead of old chain classes\n",
    "- After langchain 1.0 : langchain.chains doesn't exist\n",
    "- We will use LCEL to build RAG chains in 1.0+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d3105738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "19ba539f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x177587a70>, search_kwargs={})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert vector store to retriever\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwarg = {\"k\":3} \n",
    ")\n",
    "\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "02faa531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt Template\n",
    "\n",
    "\n",
    "system_prompt = \"\"\"  \n",
    "You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer the questions.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Context : {context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\")\n",
    "\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e38b0e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"  \\nYou are an assistant for question-answering tasks.\\nUse the following pieces of retrieved context to answer the questions.\\nIf you don't know the answer, just say that you don't know.\\nUse three sentences maximum and keep the answer concise.\\n\\nContext : {context}\\n\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf1034a",
   "metadata": {},
   "source": [
    "### Creating a Document Chain\n",
    "\n",
    "- \"Create_stuff_documents_chain\" combine all the relevant chunks and give llm as a context\n",
    "- For combining we use document chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3a54c03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"  \\nYou are an assistant for question-answering tasks.\\nUse the following pieces of retrieved context to answer the questions.\\nIf you don't know the answer, just say that you don't know.\\nUse three sentences maximum and keep the answer concise.\\n\\nContext : {context}\\n\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatAnthropic(profile={'max_input_tokens': 200000, 'max_output_tokens': 64000, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'structured_output': False}, model='claude-haiku-4-5-20251001', max_tokens=64000, temperature=0.7, anthropic_api_url='https://api.anthropic.com', anthropic_api_key=SecretStr('**********'), model_kwargs={})\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "document_chain\n",
    "\n",
    "# RunnableBinding means, it will going to execute entire Chain one by one "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33689ea",
   "metadata": {},
   "source": [
    "This Chain\n",
    "\n",
    "- Takes retrieved documents\n",
    "- \"Stuffs\" them into prompts {context} placeholder\n",
    "- Send the complete prompt to the LLM\n",
    "- Return the LLM's response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "52807be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x177587a70>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"  \\nYou are an assistant for question-answering tasks.\\nUse the following pieces of retrieved context to answer the questions.\\nIf you don't know the answer, just say that you don't know.\\nUse three sentences maximum and keep the answer concise.\\n\\nContext : {context}\\n\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "            | ChatAnthropic(profile={'max_input_tokens': 200000, 'max_output_tokens': 64000, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'structured_output': False}, model='claude-haiku-4-5-20251001', max_tokens=64000, temperature=0.7, anthropic_api_url='https://api.anthropic.com', anthropic_api_key=SecretStr('**********'), model_kwargs={})\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Final Rag chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "rag_chain = create_retrieval_chain(retriever, document_chain)\n",
    "rag_chain\n",
    "\n",
    "# retriever will fetch the relevant information\n",
    "# document_chain will process the document with the LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a5ba51b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'what is deep learning?',\n",
       " 'context': [Document(metadata={'source': '/var/folders/58/7rk_l2gn3lv73f_nlj98yjgc0000gn/T/tmpuuhmaghy/doc_1.txt'}, page_content='Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'),\n",
       "  Document(metadata={'source': '/var/folders/58/7rk_l2gn3lv73f_nlj98yjgc0000gn/T/tmpuuhmaghy/doc_1.txt'}, page_content='Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'),\n",
       "  Document(metadata={'source': '/var/folders/58/7rk_l2gn3lv73f_nlj98yjgc0000gn/T/tmpuuhmaghy/doc_1.txt'}, page_content='Deep Learning and Neural Networks'),\n",
       "  Document(metadata={'source': '/var/folders/58/7rk_l2gn3lv73f_nlj98yjgc0000gn/T/tmpuuhmaghy/doc_1.txt'}, page_content='Deep Learning and Neural Networks')],\n",
       " 'answer': 'Deep learning is a subset of machine learning based on artificial neural networks inspired by the human brain. These networks consist of layers of interconnected nodes that work together to process and learn from data. Deep learning has revolutionized fields like computer vision, natural language processing, and speech recognition.'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\"input\" : \"what is deep learning?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b25e1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question : What are the three types of machine learning\n",
      "--------------------------------------------------\n",
      "Answer : The three types of machine learning are:\n",
      "\n",
      "1. **Supervised learning** - uses labeled data to train models\n",
      "2. **Unsupervised learning** - finds patterns in unlabeled data\n",
      "3. **Reinforcement learning** - learns through interaction and feedback\n",
      "\n",
      " Retrieved Context :\n",
      "\n",
      " -- Source 1 ---\n",
      "Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are three main \n",
      "    types of machine l...\n",
      "\n",
      " -- Source 2 ---\n",
      "Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are three main \n",
      "    types of machine l...\n",
      "\n",
      " -- Source 3 ---\n",
      "Machine Learning Fundamentals...\n",
      "\n",
      " -- Source 4 ---\n",
      "Machine Learning Fundamentals...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Question : What is deep learning and how does it related to neural networks ?\n",
      "--------------------------------------------------\n",
      "Answer : Deep learning is a subset of machine learning based on artificial neural networks, which are inspired by the human brain and consist of layers of interconnected nodes. Neural networks form the foundation of deep learning, enabling it to process complex patterns in data. Deep learning has revolutionized fields like computer vision, natural language processing, and speech recognition, with specialized architectures like CNNs for images and RNNs/Transformers for sequential data.\n",
      "\n",
      " Retrieved Context :\n",
      "\n",
      " -- Source 1 ---\n",
      "Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of interconnected \n",
      "    nodes. Deep learning...\n",
      "\n",
      " -- Source 2 ---\n",
      "Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of interconnected \n",
      "    nodes. Deep learning...\n",
      "\n",
      " -- Source 3 ---\n",
      "Deep Learning and Neural Networks...\n",
      "\n",
      " -- Source 4 ---\n",
      "Deep Learning and Neural Networks...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Question : What are CNNs best used for?\n",
      "--------------------------------------------------\n",
      "Answer : Based on the context provided, Convolutional Neural Networks (CNNs) are particularly effective for **image processing**. They are one of the key deep learning architectures that have revolutionized computer vision applications.\n",
      "\n",
      " Retrieved Context :\n",
      "\n",
      " -- Source 1 ---\n",
      "Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of interconnected \n",
      "    nodes. Deep learning...\n",
      "\n",
      " -- Source 2 ---\n",
      "Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of interconnected \n",
      "    nodes. Deep learning...\n",
      "\n",
      " -- Source 3 ---\n",
      "Deep Learning and Neural Networks...\n",
      "\n",
      " -- Source 4 ---\n",
      "Deep Learning and Neural Networks...\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to query the modern RAG system\n",
    "\n",
    "def query_rag_modern(question) :\n",
    "    print(f\"Question : {question}\")\n",
    "    print(\"-\"*50)\n",
    "\n",
    "\n",
    "    # using create_retrieval_chain approach\n",
    "    \n",
    "    result = rag_chain.invoke({\"input\" : question})\n",
    "\n",
    "    print(f\"Answer : {result['answer']}\")\n",
    "    print(\"\\n Retrieved Context :\")\n",
    "\n",
    "    for i, doc in enumerate(result['context']):\n",
    "        print(f\"\\n -- Source {i+1} ---\")\n",
    "        print(doc.page_content[:200] + \"...\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test Questions\n",
    "test_questions = [\n",
    "    \"What are the three types of machine learning\",\n",
    "    \"What is deep learning and how does it related to neural networks ?\",\n",
    "    \"What are CNNs best used for?\"\n",
    "]\n",
    "\n",
    "for question in test_questions :\n",
    "    result = query_rag_modern(question)\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe16813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "249b7551",
   "metadata": {},
   "source": [
    "### Building RAG using LCEL (LangChain Expression Language)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0d36a50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cdf3ae4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\" \\n    Use the following context to answer the question.\\n    If you don't know the answer based on the context, say you don't know.\\n    Provide specific detail from the context to support your answer\\n    Context : {context}\\n\\n    Question : {question}\\n    Answer :\\n    \"), additional_kwargs={})])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\" \n",
    "    Use the following context to answer the question.\n",
    "    If you don't know the answer based on the context, say you don't know.\n",
    "    Provide specific detail from the context to support your answer\n",
    "    Context : {context}\n",
    "\n",
    "    Question : {question}\n",
    "    Answer :\n",
    "    \"\"\"\n",
    ")\n",
    "custom_prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f149baf",
   "metadata": {},
   "source": [
    "### Create RAG Chain Alternative - Using LCEL(Langchain Expression Language)\n",
    "- Creating your own chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "851bc4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c802b26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"\\n    Use the following context to answer the questions. If you don't know the answer based on the context, say you don't know.\\n    Provide specific details from the context to support your answer\\n\\n    Context : {context}\\n\\n\\n    Question : {question}\\n\\n    Answer :\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt Template\n",
    "\n",
    "custom_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Use the following context to answer the questions. If you don't know the answer based on the context, say you don't know.\n",
    "    Provide specific details from the context to support your answer\n",
    "\n",
    "    Context : {context}\n",
    "\n",
    "\n",
    "    Question : {question}\n",
    "\n",
    "    Answer :\"\"\"\n",
    ")\n",
    "custom_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e98628d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the output document for the prompt\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5d387baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x177587a70>, search_kwargs={})\n",
       "           | RunnableLambda(format_docs),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"\\n    Use the following context to answer the questions. If you don't know the answer based on the context, say you don't know.\\n    Provide specific details from the context to support your answer\\n\\n    Context : {context}\\n\\n\\n    Question : {question}\\n\\n    Answer :\"), additional_kwargs={})])\n",
       "| ChatAnthropic(profile={'max_input_tokens': 200000, 'max_output_tokens': 64000, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'structured_output': False}, model='claude-haiku-4-5-20251001', max_tokens=64000, temperature=0.7, anthropic_api_url='https://api.anthropic.com', anthropic_api_key=SecretStr('**********'), model_kwargs={})\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the RAG Chain Using LCEL\n",
    "rag_chain_lcel = ({\"context\" : retriever | format_docs,\n",
    "                 \"question\" : RunnablePassthrough() }\n",
    "                | custom_prompt\n",
    "                | llm\n",
    "                | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_lcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4df6c7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# What is Deep Learning?\\n\\nBased on the context provided:\\n\\n**Deep learning is a subset of machine learning based on artificial neural networks.** These networks are inspired by the human brain and consist of layers of interconnected nodes.\\n\\n## Key Characteristics:\\n\\n- **Foundation**: Built on artificial neural networks inspired by the human brain\\n- **Structure**: Organized in layers of interconnected nodes\\n- **Impact**: Has revolutionized several fields including:\\n  - Computer vision\\n  - Natural language processing\\n  - Speech recognition\\n\\n## Common Applications:\\n\\n- **Convolutional Neural Networks (CNNs)**: Particularly effective for image processing\\n- **Recurrent Neural Networks (RNNs)** and **Transformers**: Used for sequential data and language tasks\\n\\nIn essence, deep learning is a powerful approach within machine learning that uses layered neural networks to learn complex patterns from data.'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain_lcel.invoke(\"what's deep learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4138e6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '/var/folders/58/7rk_l2gn3lv73f_nlj98yjgc0000gn/T/tmpuuhmaghy/doc_1.txt'}, page_content='Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'), Document(metadata={'source': '/var/folders/58/7rk_l2gn3lv73f_nlj98yjgc0000gn/T/tmpuuhmaghy/doc_1.txt'}, page_content='Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'), Document(metadata={'source': '/var/folders/58/7rk_l2gn3lv73f_nlj98yjgc0000gn/T/tmpuuhmaghy/doc_1.txt'}, page_content='Deep Learning and Neural Networks'), Document(metadata={'source': '/var/folders/58/7rk_l2gn3lv73f_nlj98yjgc0000gn/T/tmpuuhmaghy/doc_1.txt'}, page_content='Deep Learning and Neural Networks')]\n"
     ]
    }
   ],
   "source": [
    "#retriever.get_relevant_documents(\"what's deep learning\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b206c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query using LCEL approach - Fixed Version\n",
    "\n",
    "def query_rag_lcel(question):\n",
    "    print(f\"Question : {question}\")\n",
    "    print(\"-\"*50)\n",
    "\n",
    "\n",
    "    # m1 : Pass String directly when use RunnablePassThrough - directly has to give the string\n",
    "    answer = rag_chain_lcel.invoke(question)\n",
    "    print(f\"Answer : {answer}\")\n",
    "\n",
    "\n",
    "    # Get source documents seperately if needed\n",
    "    docs = retriever.invoke(question)\n",
    "    print(\"Source Documents : \")\n",
    "\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(f\"\\n----Source{i+1} ---\")\n",
    "        print(doc.page_content[:200] + \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "58ff9398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question : what are the key concepts of reinforcement learning\n",
      "--------------------------------------------------\n",
      "Answer : Based on the provided context, I don't have enough information to fully answer your question about the key concepts of reinforcement learning.\n",
      "\n",
      "The context mentions that reinforcement learning is one of the three main types of machine learning and that it \"learns through,\" but the explanation is incomplete - it cuts off mid-sentence and doesn't provide the details about how reinforcement learning works or what its key concepts are.\n",
      "\n",
      "To properly answer your question, I would need a more complete description of reinforcement learning in the context provided.\n",
      "Source Documents : \n",
      "\n",
      "----Source1 ---\n",
      "Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are three main \n",
      "    types of machine l...\n",
      "\n",
      "----Source2 ---\n",
      "Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are three main \n",
      "    types of machine l...\n",
      "\n",
      "----Source3 ---\n",
      "Machine Learning Fundamentals...\n",
      "\n",
      "----Source4 ---\n",
      "Machine Learning Fundamentals...\n"
     ]
    }
   ],
   "source": [
    "query_rag_lcel(\"what are the key concepts of reinforcement learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4273fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
